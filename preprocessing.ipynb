{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3077a741-db52-4d5f-a94a-f8f3b144dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import torch; torch.utils.backcompat.broadcast_warning.enabled = True\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.backends.cudnn as cudnn; cudnn.benchmark = True\n",
    "from scipy.fftpack import fft, rfft, fftfreq, irfft, ifft, rfftfreq\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import importlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c280e978-1a38-4ba9-80cc-d5ebdcab7096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.1\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30859550-c766-4fdc-b52a-41e38569f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_signals_path = \"/media/NAS/EEG2IMAGE/eeg_cvpr_2017/data/eeg_5_95_std.pth\"\n",
    "img_path = '/media/NAS/EEG2IMAGE/eeg_cvpr_2017/image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b75008-dd13-4181-a159-3cb8c16fd2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Load...\n"
     ]
    }
   ],
   "source": [
    "class EEGDataset:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, eeg_signals_path, eeg_data_path):\n",
    "        # Load EEG signals\n",
    "        print(\"Start Load...\")\n",
    "        loaded = torch.load(eeg_signals_path)\n",
    "        # if opt.subject!=0:\n",
    "        #     self.data = [loaded['dataset'][i] for i in range(len(loaded['dataset']) ) if loaded['dataset'][i]['subject']==0]\n",
    "        # else:\n",
    "        self.data=loaded['dataset']        \n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "        self.image_path = eeg_data_path\n",
    "        \n",
    "        # Compute size\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    # Get size\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    # Get item\n",
    "    def __getitem__(self, i):\n",
    "        # Process EEG\n",
    "        eeg = self.data[i][\"eeg\"].float().t()\n",
    "        eeg = eeg[20:460,:]\n",
    "\n",
    "        # if opt.model_type == \"model10\":\n",
    "        #     eeg = eeg.t()\n",
    "        #     eeg = eeg.view(1,128,460-20)\n",
    "        # Get label        \n",
    "        label = self.data[i][\"label\"]\n",
    "\n",
    "        # Get Original Image\n",
    "        image = self.images[self.data[i][\"image\"]]\n",
    "\n",
    "        # Return\n",
    "        return eeg, image, label\n",
    "\n",
    "# Splitter class\n",
    "class Splitter:\n",
    "\n",
    "    def __init__(self, dataset, split_path, split_num=0, split_name=\"train\"):\n",
    "        # Set EEG dataset\n",
    "        self.dataset = dataset\n",
    "        # Load split\n",
    "        loaded = torch.load(split_path)\n",
    "        self.split_idx = loaded[\"splits\"][split_num][split_name]\n",
    "        # Filter data\n",
    "        self.split_idx = [i for i in self.split_idx if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600]\n",
    "        # Compute size\n",
    "        self.size = len(self.split_idx)\n",
    "\n",
    "    # Get size\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    # Get item\n",
    "    def __getitem__(self, i):\n",
    "        # Get sample from dataset\n",
    "        eeg, image, label = self.dataset[self.split_idx[i]]\n",
    "        # Return\n",
    "        return eeg, image, label\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = EEGDataset(eeg_signals_path = eeg_signals_path,  eeg_data_path = img_path)\n",
    "# Create loaders\n",
    "loaders = {split: DataLoader(Splitter(dataset, split_path = \"/media/NAS/EEG2IMAGE/eeg_cvpr_2017/data/block_splits_by_image_all.pth\", \n",
    "                                      split_num = 0, \n",
    "                                      split_name = split), 1, drop_last = False, shuffle = False) for split in [\"train\", \"val\", \"test\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97e5828-dfbc-453a-bfa9-800f995fe110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Load...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EEGPreDataset:\n",
    "\n",
    "    # Constructo\n",
    "    def __init__(self, eeg_pre_path, eeg_data_path, transforms=None):\n",
    "        # Load EEG signals\n",
    "        print(\"Start Load...\")\n",
    "        # loaded = torch.load(eeg_signals_path)\n",
    "\n",
    "        # split_loaded = torch.load(split_path)\n",
    "        # if opt.subject!=0:\n",
    "        #     self.data = [loaded['dataset'][i] for i in range(len(loaded['dataset']) ) if loaded['dataset'][i]['subject']==0]\n",
    "        # # else:\n",
    "        # self.data=loaded['dataset']        \n",
    "        # self.labels = loaded[\"labels\"]\n",
    "        # self.images = loaded[\"images\"]\n",
    "        self.image_path = eeg_data_path\n",
    "        self.data = glob.glob(os.path.join(eeg_pre_path, \"*\"))\n",
    "\n",
    "        # Compute size\n",
    "        self.dataset_size = len(self.data)\n",
    "\n",
    "        \n",
    "        # Transforms\n",
    "        self.transforms = transforms\n",
    "        # self.to_tensor  = ToTensor()\n",
    "\n",
    "    # Get size\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    # Get item\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        loaded = torch.load(self.data[i])\n",
    "        # Process EEG\n",
    "        eeg = loaded[\"eeg\"]\n",
    "\n",
    "        # Get label        \n",
    "        label = loaded[\"label\"]\n",
    "\n",
    "        # Get Original Image\n",
    "        image_name = loaded[\"image\"]\n",
    "        s, _ = image_name.split(\"_\")\n",
    "        image = torch.empty((224,224))\n",
    "        if os.path.exists(os.path.join(self.image_path, s, image_name+\".JPEG\")):\n",
    "            image = cv2.imread(os.path.join(self.image_path, s, image_name+\".JPEG\"))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.\n",
    "        else:\n",
    "            print(os.path.join(self.image_path, s, image_name+\".JPEG\"))\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        # \n",
    "        # image = self.to_tensor(image)\n",
    "        \n",
    "        # Return\n",
    "        return eeg, image, label\n",
    "\n",
    "dataset = EEGPreDataset(os.path.join(\".\",\"preprocessing_data\",\"train\") , img_path)\n",
    "loaders = DataLoader(dataset, 1, drop_last = False, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22159b3f-556b-4265-be01-88fa80fc45bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m file_name  \u001b[38;5;241m=\u001b[39m eeg_signals_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[43mloaders\u001b[49m[split]), total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(loaders[split]), desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data preprocessing...\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m         data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m:data[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()}\n\u001b[1;32m     10\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(data, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, split, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaders' is not defined"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from tqdm.notebook  import tqdm\n",
    "\n",
    "path = os.path.join(\".\",\"preprocessing_data\")\n",
    "file_name  = eeg_signals_path.split(\"/\")[-1].replace(\".pth\", \"\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for idx, data in tqdm(enumerate(loaders[split]), total = len(loaders[split]), desc = f\"{split} data preprocessing...\"):\n",
    "        data = {\"eeg\":data[0].numpy().squeeze(), \"image\":data[1][0], \"label\":data[2].item()}\n",
    "        torch.save(data, os.path.join(path, split, f\"{file_name}_{idx}.pth\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e47e4a-62fa-4cb7-bbd6-c7f9564901ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['eeg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953599d6-7322-4a20-8533-e1770f5d8da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.load(os.path.join(path, split, f\"{file_name}_{idx}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c2739-96b2-4e32-9a7d-24438e503b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = dataset.images[dataset.data[1][\"image\"]]\n",
    "s, _ = image_name.split(\"_\")\n",
    "image = cv2.imread(os.path.join(dataset.image_path, s, image_name+\".JPEG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6f6225-3b33-4aae-b911-f4350f518c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in loaders:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
